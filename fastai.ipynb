{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Precision-Recall curve for a specific class\n",
    "def plot_precision_recall_curve(class_index, preds, targets):\n",
    "    precision, recall, _ = precision_recall_curve(\n",
    "        targets.numpy()[:, class_index], preds.numpy()[:, class_index]\n",
    "    )\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, marker=\".\")\n",
    "    plt.title(f\"Precision-Recall Curve for Class {class_index}\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def per_class_accuracy(\n",
    "    class_index,\n",
    "    preds,\n",
    "    targets,\n",
    "):\n",
    "    class_preds = preds.argmax(dim=1)\n",
    "    class_targets = targets == class_index\n",
    "    class_preds = class_preds[class_targets]\n",
    "    acc = accuracy_score(class_targets.numpy(), class_preds.numpy())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = np.load(\"class_names.npy\", allow_pickle=True)\n",
    "# print(class_names.item())\n",
    "\n",
    "attributes = np.load(\"attributes.npy\", allow_pickle=True)\n",
    "attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_images.csv\")\n",
    "test_df = pd.read_csv(\"test_images_path.csv\")\n",
    "\n",
    "dls = ImageDataLoaders.from_df(\n",
    "    train_df,\n",
    "    valid_pct=0.2,\n",
    "    item_tfms=Resize(224),\n",
    "    bs=64,\n",
    "    label_col=\"label\",\n",
    "    fn_col=\"image_path\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.train.item_tfms = [\n",
    "    RandomResizedCrop(224, min_scale=0.5),\n",
    "    Rotate(),\n",
    "    Flip(),\n",
    "    Dihedral(),\n",
    "    Brightness(),\n",
    "    Contrast(),\n",
    "    Saturation(),\n",
    "    Hue(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(20, 20), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = dls.test_dl(test_df, with_labels=True)\n",
    "predictions, targets = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy(predictions, targets)\n",
    "print(f\"Accuracy: {acc.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for class 0\n",
    "plot_precision_recall_curve(0, predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example accuracy for class 0\n",
    "acc_class_0 = per_class_accuracy(predictions, targets, 0)\n",
    "print(f\"Accuracy for class 0: {acc_class_0:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = np.argmax(predictions, axis=1)\n",
    "plt.hist(class_preds, bins=len(dls.vocab))\n",
    "plt.title(\"Histogram of Predicted Classes\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a submission DataFrame\n",
    "submission_df = test_df.copy()\n",
    "submission_df[\"label\"] = predicted_labels\n",
    "\n",
    "# Optional: if your test_df contains a column that represents an ID, use that instead\n",
    "# For example, if there's an 'image_id' column:\n",
    "# submission_df = pd.DataFrame({\"id\": test_df[\"image_id\"], \"label\": predicted_labels})\n",
    "\n",
    "# Save the submission file\n",
    "submission_df[[\"id\", \"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
